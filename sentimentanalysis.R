library("tm")
library("rJava")
library("wordcloud")
library("textir")
library("RWeka")
library("qdap")
library("maptpx")
library("readr")
library("ngram")
library("SnowballC")
library("NLP")
library("DTMCPack")
 install.packages("ngram")
library("ngram")
demonetization_tweets <- read_csv("D:/1 DATA BYTE/1_projects/demonetization proj/from shivani/demonetization-tweets.csv")
tweet = demonetization_tweets$text
#tweet <- tweet.clean(tweet)
tweet = gsub("[[:cntrl:]]", " ", tweet)
tweet <- gsub("(RT|via)((?:\\b\\W*@\\W+)+)", " ", tweet, ignore.case = T)
tweet <- gsub('@\\w+', '', tweet)
tweet <- gsub("[[:punct:]]"," ", tweet)
tweet <- gsub("[[:digit:]]"," ", tweet)
tweet <- gsub("http[s]?\\w+", " ", tweet)
tweet <- gsub("[ \t]{2,}", " ", tweet)
tweet <- gsub("^\\s+|\\s+$", " ", tweet)
tweet <- tweet[!is.na(tweet)]
tweet = gsub("^ ", "", tweet)
tweet = gsub(" $", "", tweet)
tweet = gsub("[^[:alnum:] ]", " ", tweet)
tweet = tolower(tweet)

negative_words <- read_csv("~/R/negative-words.txt")
positive_words <- read_csv("~/R/positive-words.txt")

tweet_corpus = Corpus(VectorSource(tweet))
#tweet_corpus<-tm_map(tweet_corpus, PlainTextDocument,mc.cores=1)

#tweet_corpus = ngrams(tweet_corpus,"bi",3)
tweet_corpus = ngrams(tweet_corpus,"tri",5)
#dtm1 = custom.dtm(tweet_corpus,"tf")
dtm1 <- DocumentTermMatrix(c, control = list(tokenize = BigramTokenizer))

dtm2 = custom.dtm(tweet_corpus,"tfidf") 

freq1 = sort(apply(dtm1,2,sum),decreasing = T)
windows()
wordcloud(names(freq1),freq1, min.freq = 150, max.words = 300, random.order = 'F', rot.per = 0.2, colors = brewer.pal(8, "Dark2"), scale = c(4,0.5))
title(sub = "Term frequency - wordcloud")
freq2 = sort(apply(dtm2,2,sum),decreasing = T)
windows()
wordcloud(names(freq2),freq2, min.freq = 150, max.words = 300, random.order = 'F', rot.per = 0.2, colors = brewer.pal(8, "Dark2"), scale = c(4,0.5))
title(sub = "Term frequency - wordcloud")
  
